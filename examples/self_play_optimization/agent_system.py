"""
Self-play agent system for two-player optimization game.

This implements the SLIME custom generate function interface for a two-player
dialogue game where:
- Both players use the same model
- Each player maintains their own conversation history
- Observations are asymmetric (each player sees different views)
- ONE Sample per player per game (not per turn!)
- The Sample contains the FULL conversation with loss_mask for all generated tokens
"""

import asyncio
from concurrent.futures import ThreadPoolExecutor
from copy import deepcopy
from functools import partial
from dataclasses import dataclass, field
from typing import Any

from slime.utils.http_utils import post
from slime.utils.types import Sample


@dataclass
class TurnResult:
    """Result of a single turn's generation."""
    response_text: str
    response_tokens: list[int]
    logprobs: list[float]
    status: str  # "completed", "truncated", "length"


@dataclass
class PlayerState:
    """Tracks conversation state for a single player."""
    messages: list = field(default_factory=list)
    # Accumulate tokens and logprobs across ALL turns
    all_response_tokens: list = field(default_factory=list)  # List of (tokens, logprobs) per turn
    all_logprobs: list = field(default_factory=list)


async def generate_turn(args, messages: list) -> TurnResult:
    """Generate a single turn response.

    This does NOT create a Sample - it just generates and returns the raw result.
    Samples are created at game end with the full conversation.

    Args:
        args: Arguments containing sglang connection info, tokenizer, etc.
        messages: The conversation history up to this point

    Returns:
        TurnResult with response text, tokens, and logprobs
    """
    sampling_params = args.sampling_params
    tokenizer = args.tokenizer
    max_context_length = args.rollout_max_context_len

    url = f"http://{args.sglang_router_ip}:{args.sglang_router_port}/generate"

    # Apply chat template
    prompt_text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
        **(getattr(args, 'apply_chat_template_kwargs', None) or {}),
    )

    prompt_token_ids = tokenizer(prompt_text, add_special_tokens=False)["input_ids"]
    prompt_length = len(prompt_token_ids)

    current_sampling_params = deepcopy(sampling_params)
    current_sampling_params["max_new_tokens"] = min(
        sampling_params["max_new_tokens"],
        max_context_length - prompt_length
    )

    if current_sampling_params["max_new_tokens"] <= 0:
        raise RuntimeError(f"No room for generation: prompt_length={prompt_length}, max_context={max_context_length}")

    payload = {
        "input_ids": prompt_token_ids,
        "sampling_params": current_sampling_params,
        "return_logprob": True
    }

    output = await post(url, payload)

    # Extract response tokens and logprobs
    if "output_token_logprobs" in output["meta_info"]:
        response_tokens = [item[1] for item in output["meta_info"]["output_token_logprobs"]]
        logprobs = [item[0] for item in output["meta_info"]["output_token_logprobs"]]
    else:
        response_tokens = []
        logprobs = []

    # Determine status
    finish_reason = output["meta_info"]["finish_reason"]["type"]
    if finish_reason == "length":
        status = "truncated"
    else:
        status = "completed"

    return TurnResult(
        response_text=output["text"],
        response_tokens=response_tokens,
        logprobs=logprobs,
        status=status,
    )


def build_player_sample(
    args,
    base_sample: Sample,
    player_key: str,
    messages: list,
    turn_results: list[TurnResult],
    reward: float,
    group_index: int | None,
) -> Sample:
    """Build a single Sample for a player's complete game.

    The Sample contains:
    - tokens: Full tokenized conversation
    - loss_mask: 1s for ALL tokens generated by this player (across all turns)
    - rollout_log_probs: Logprobs for generated tokens (0 for prompt tokens)
    - reward: Single scalar game reward

    Args:
        args: SLIME args with tokenizer
        base_sample: Base sample to copy metadata from
        player_key: "player-1" or "player-2"
        messages: Complete conversation from this player's perspective
        turn_results: List of TurnResult for each turn this player took
        reward: Game reward
        group_index: GRPO group index

    Returns:
        Sample ready for training
    """
    tokenizer = args.tokenizer

    # Tokenize the FULL conversation (with all messages, no generation prompt)
    full_text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=False,
    )
    full_tokens = tokenizer(full_text, add_special_tokens=False)["input_ids"]

    # Build loss_mask by finding where each response appears in the full sequence
    # loss_mask[i] = 1 if token i was generated by this player, 0 otherwise
    loss_mask = [0] * len(full_tokens)
    logprob_tensor = [0.0] * len(full_tokens)

    # Strategy: for each turn's response tokens, find them in the full sequence
    # and mark those positions in loss_mask

    # Collect all response tokens with their logprobs
    all_response_tokens = []
    all_logprobs = []
    for turn in turn_results:
        all_response_tokens.extend(turn.response_tokens)
        all_logprobs.extend(turn.logprobs)

    # Find and mark response tokens in full sequence
    # We scan through full_tokens looking for matches with response tokens
    response_idx = 0
    for i, token in enumerate(full_tokens):
        if response_idx < len(all_response_tokens):
            if token == all_response_tokens[response_idx]:
                loss_mask[i] = 1
                logprob_tensor[i] = all_logprobs[response_idx]
                response_idx += 1

    # Verify we found all response tokens
    if response_idx != len(all_response_tokens):
        # This can happen due to tokenization differences; log but don't fail
        print(f"Warning: Only matched {response_idx}/{len(all_response_tokens)} response tokens for {player_key}")

    # Create sample
    sample = deepcopy(base_sample)
    sample.tokens = full_tokens
    sample.loss_mask = loss_mask
    sample.rollout_log_probs = logprob_tensor
    sample.reward = reward
    sample.group_index = group_index
    sample.player = player_key
    # response_length must match loss_mask length - it's used to split concatenated batches
    # loss_mask has 1s for generated tokens, 0s for prompt/observation tokens
    sample.response_length = len(full_tokens)

    # Set status based on last turn
    if turn_results:
        last_status = turn_results[-1].status
        if last_status == "truncated":
            sample.status = Sample.Status.TRUNCATED
        else:
            sample.status = Sample.Status.COMPLETED
    else:
        sample.status = Sample.Status.COMPLETED

    # Store the full conversation text for debugging
    sample.response = full_text

    return sample


async def run_self_play_game(
    args,
    sample: Sample,
    env,
    max_turns: int = 30,
    max_retries_per_turn: int = 8,
) -> list[Sample]:
    """
    Run a two-player self-play game and return ONE Sample per player.

    Each Sample contains the FULL conversation from that player's perspective,
    with loss_mask marking all tokens that player generated across all turns.

    Args:
        args: SLIME args with sglang connection, tokenizer, sampling params
        sample: Base sample (contains game_state for environment reset)
        env: The game environment (e.g., OptimizationEnv)
        max_turns: Maximum turns before terminating
        max_retries_per_turn: Maximum retries per turn on errors

    Returns:
        List of 2 Sample objects (one per player)
    """
    args = deepcopy(args)
    base_sample = sample

    # Initialize player states
    players = {
        "player-1": PlayerState(),
        "player-2": PlayerState(),
    }

    # Track turn results for each player (for building loss_mask later)
    player_turn_results: dict[str, list[TurnResult]] = {
        "player-1": [],
        "player-2": [],
    }

    # Reset environment
    # Use group_index as seed so all samples in the same GRPO group play the same game
    # NOTE: env.reset() uses Jinja2 which calls asyncio.run() internally,
    # so we must run it in a thread to avoid "cannot be called from a running event loop"
    game_state = getattr(sample, 'game_state', None)
    game_seed = getattr(sample, 'group_index', None)
    obss = await asyncio.to_thread(env.reset, game_state=game_state, seed=game_seed)

    # Initialize each player's conversation with their observation
    for player_key in ["player-1", "player-2"]:
        if obss.get(player_key):
            players[player_key].messages.append({
                "role": "user",
                "content": obss[player_key]
            })

    turn_count = 0
    retry_count = 0

    while not obss.get("done", False) and turn_count < max_turns:
        current_player = obss["turn_player"]
        player_state = players[current_player]

        try:
            # Generate response
            turn_result = await generate_turn(args, player_state.messages)

            # Add assistant response to current player's history
            player_state.messages.append({
                "role": "assistant",
                "content": turn_result.response_text
            })

            # Store turn result for later loss_mask building
            player_turn_results[current_player].append(turn_result)

            # Step the environment (run in thread due to Jinja2 async issue)
            obss, is_error = await asyncio.to_thread(env.step, turn_result.response_text)

            if is_error:
                retry_count += 1
                if retry_count >= max_retries_per_turn:
                    break
                # On error, only current player gets feedback
                if obss.get(current_player):
                    player_state.messages.append({
                        "role": "user",
                        "content": obss[current_player]
                    })
            else:
                # Successful turn
                retry_count = 0
                turn_count += 1

                # Only the OTHER player observes
                other_player = "player-2" if current_player == "player-1" else "player-1"
                obs = obss.get(other_player, "")
                if obs:
                    players[other_player].messages.append({
                        "role": "user",
                        "content": obs
                    })

        except Exception as e:
            print(f"Error during generation for {current_player}: {e}")
            break

    # Compute reward
    info = obss.get("info", {})
    reward = info.get("score_norm", 0.0)
    if hasattr(env, 'get_penalized_reward'):
        reward = env.get_penalized_reward(reward)

    # Get group_index from the original sample
    group_index = getattr(base_sample, 'group_index', None)

    # Build ONE Sample per player
    samples = []
    for player_key in ["player-1", "player-2"]:
        player_sample = build_player_sample(
            args=args,
            base_sample=base_sample,
            player_key=player_key,
            messages=players[player_key].messages,
            turn_results=player_turn_results[player_key],
            reward=reward,
            group_index=group_index,
        )
        samples.append(player_sample)

    return samples


# ============================================================================
# Testing utilities (unchanged from before)
# ============================================================================

def merge_consecutive_user_messages(messages: list[dict]) -> list[dict]:
    """Merge consecutive user messages into single messages."""
    if not messages:
        return []

    merged = []
    current_role = None
    current_content_parts = []

    for msg in messages:
        if msg["role"] == current_role == "user":
            current_content_parts.append(msg["content"])
        else:
            if current_content_parts:
                merged.append({
                    "role": current_role,
                    "content": "\n\n".join(current_content_parts)
                })
            current_role = msg["role"]
            current_content_parts = [msg["content"]]

    if current_content_parts:
        merged.append({
            "role": current_role,
            "content": "\n\n".join(current_content_parts)
        })

    return merged


def get_player_conversations(
    env,
    game_state: dict | None = None,
    responses: list[tuple[str, str]] | None = None,
    merge_user_messages: bool = False,
) -> dict[str, list[dict]]:
    """Simulate a game and return conversation histories for each player."""
    players = {
        "player-1": [],
        "player-2": [],
    }

    obss = env.reset(game_state=game_state)

    for player_key in ["player-1", "player-2"]:
        if obss.get(player_key):
            players[player_key].append({
                "role": "user",
                "content": obss[player_key]
            })

    if responses is None:
        return players

    for expected_player, response in responses:
        if obss.get("done"):
            break

        current_player = obss["turn_player"]
        assert current_player == expected_player, \
            f"Expected {expected_player}'s turn but got {current_player}"

        players[current_player].append({
            "role": "assistant",
            "content": response
        })

        obss, is_error = env.step(response)

        if is_error:
            obs = obss.get(current_player, "")
            if obs:
                players[current_player].append({
                    "role": "user",
                    "content": obs
                })
        else:
            other_player = "player-2" if current_player == "player-1" else "player-1"
            obs = obss.get(other_player, "")
            if obs:
                players[other_player].append({
                    "role": "user",
                    "content": obs
                })

    if merge_user_messages:
        return {
            player_key: merge_consecutive_user_messages(msgs)
            for player_key, msgs in players.items()
        }

    return players
